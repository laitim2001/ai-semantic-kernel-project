# Docker å®¹å™¨åŒ–å®Œæ•´æŒ‡å—

**ç‰ˆæœ¬**: 1.0.0
**æœ€å¾Œæ›´æ–°**: 2025-11-01
**æ–‡æª”ç‹€æ…‹**: âœ… å®Œæ•´
**é©ç”¨ç’°å¢ƒ**: Development, Staging, Production

---

## ğŸ“‹ æ–‡æª”æ¦‚è¿°

æœ¬æ–‡æª”æä¾› AI Workflow Platform çš„å®Œæ•´ Docker å®¹å™¨åŒ–æ–¹æ¡ˆ,åŒ…æ‹¬æ‰€æœ‰å¾®æœå‹™çš„ Dockerfileã€Docker Compose é…ç½®ã€å¤šéšæ®µæ§‹å»ºå„ªåŒ–å’Œå®¹å™¨å®‰å…¨æœ€ä½³å¯¦è¸ã€‚

### ç›®æ¨™è®€è€…
- DevOps å·¥ç¨‹å¸«
- å¾Œç«¯é–‹ç™¼å·¥ç¨‹å¸«
- ç³»çµ±æ¶æ§‹å¸«
- é‹ç¶­åœ˜éšŠ

### å‰ç½®éœ€æ±‚
```yaml
å·¥å…·ç‰ˆæœ¬:
  Docker Engine: â‰¥24.0
  Docker Compose: â‰¥2.20
  BuildKit: Enabled (export DOCKER_BUILDKIT=1)

ç³»çµ±è¦æ±‚:
  OS: Linux/macOS/Windows with WSL2
  RAM: â‰¥8GB (é–‹ç™¼ç’°å¢ƒ), â‰¥16GB (ç”Ÿç”¢ç’°å¢ƒ)
  Disk: â‰¥50GB
```

---

## ğŸ—ï¸ å®¹å™¨åŒ–æ¶æ§‹æ¦‚è¦½

### æœå‹™å®¹å™¨æ¸…å–®

```yaml
å¾Œç«¯æœå‹™ (5 å€‹å®¹å™¨):
  1. api-gateway          # ASP.NET Core API Gateway (Port 5000)
  2. agent-service        # Agent ç®¡ç†æœå‹™ (Port 5001)
  3. workflow-service     # å·¥ä½œæµå¼•æ“æœå‹™ (Port 5002)
  4. plugin-service       # Plugin åŸ·è¡Œæœå‹™ (Port 5003)
  5. execution-service    # ä»£ç¢¼åŸ·è¡Œæœå‹™ (Port 5004)

å‰ç«¯æœå‹™ (2 å€‹å®¹å™¨):
  6. frontend-host        # React ä¸»æ‡‰ç”¨ (Port 3000)
  7. frontend-remote      # Vue å·¥ä½œæµç·¨è¼¯å™¨ (Port 3001)

åŸºç¤è¨­æ–½æœå‹™ (6 å€‹å®¹å™¨):
  8. postgres             # PostgreSQL 16 (Port 5432)
  9. redis                # Redis 7 (Port 6379)
  10. rabbitmq            # RabbitMQ 3.12 (Port 5672, 15672)
  11. nginx               # NGINX Reverse Proxy (Port 80, 443)
  12. websocket-server    # WebSocket å”ä½œæœå‹™ (Port 3002)
  13. monitoring          # Prometheus + Grafana

ç¸½è¨ˆ: 13 å€‹å®¹å™¨
```

### å®¹å™¨ç¶²çµ¡æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Docker Host                           â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚           Network: ai-workflow-network              â”‚ â”‚
â”‚  â”‚              (bridge mode)                          â”‚ â”‚
â”‚  â”‚                                                     â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚ â”‚
â”‚  â”‚  â”‚  NGINX   â”‚  â”‚   API    â”‚  â”‚ Frontend â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  :80/443 â”‚  â”‚  Gateway â”‚  â”‚   :3000  â”‚         â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚ â”‚
â”‚  â”‚       â”‚             â”‚             â”‚                â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”         â”‚ â”‚
â”‚  â”‚  â”‚       Internal Service Network        â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”    â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚Agentâ”‚ â”‚Work â”‚ â”‚Plug â”‚ â”‚Exec â”‚    â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚:5001â”‚ â”‚:5002â”‚ â”‚:5003â”‚ â”‚:5004â”‚    â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”˜    â”‚         â”‚ â”‚
â”‚  â”‚  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚         â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”‚
â”‚  â”‚                   â”‚                                 â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚ â”‚
â”‚  â”‚  â”‚       Data Layer                      â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”   â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚PostgreSQLâ”‚  â”‚ Redisâ”‚  â”‚RabbitMQ   â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  :5432   â”‚  â”‚ :6379â”‚  â”‚ :5672â”‚   â”‚         â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜   â”‚         â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                          â”‚
â”‚  Volumes (Persistent Storage):                          â”‚
â”‚  - postgres-data    (PostgreSQL æ•¸æ“šæŒä¹…åŒ–)              â”‚
â”‚  - redis-data       (Redis æŒä¹…åŒ–)                      â”‚
â”‚  - rabbitmq-data    (RabbitMQ æŒä¹…åŒ–)                   â”‚
â”‚  - nginx-certs      (SSL è­‰æ›¸)                          â”‚
â”‚  - app-logs         (æ‡‰ç”¨æ—¥èªŒ)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Dockerfile è©³ç´°è¨­è¨ˆ

### 1. API Gateway Dockerfile (Multi-stage Build)

```dockerfile
# File: src/ApiGateway/Dockerfile
# å¤šéšæ®µæ§‹å»º: Build â†’ Test â†’ Publish â†’ Runtime
# å„ªåŒ–: æœ€å°é¡åƒå¤§å°, å®‰å…¨åŠ å›º, ç·©å­˜å±¤å„ªåŒ–

# ============================================
# Stage 1: Build Base
# ============================================
FROM mcr.microsoft.com/dotnet/sdk:8.0-alpine AS build-base
WORKDIR /src

# å®‰è£æ§‹å»ºå·¥å…·
RUN apk add --no-cache \
    git \
    ca-certificates \
    && update-ca-certificates

# è¤‡è£½è§£æ±ºæ–¹æ¡ˆæ–‡ä»¶å’Œé …ç›®æ–‡ä»¶ï¼ˆç·©å­˜å±¤å„ªåŒ–ï¼‰
COPY ["Directory.Build.props", "./"]
COPY ["nuget.config", "./"]
COPY ["*.sln", "./"]

# è¤‡è£½æ‰€æœ‰é …ç›®çš„ .csproj æ–‡ä»¶
COPY ["src/ApiGateway/ApiGateway.csproj", "src/ApiGateway/"]
COPY ["src/Core/Core.csproj", "src/Core/"]
COPY ["src/Infrastructure/Infrastructure.csproj", "src/Infrastructure/"]
COPY ["src/Shared/Shared.csproj", "src/Shared/"]

# é‚„åŸ NuGet ä¾è³´ï¼ˆç¨ç«‹ç·©å­˜å±¤ï¼‰
RUN dotnet restore "src/ApiGateway/ApiGateway.csproj" \
    --runtime linux-musl-x64

# ============================================
# Stage 2: Build
# ============================================
FROM build-base AS build
WORKDIR /src

# è¤‡è£½æ‰€æœ‰æºä»£ç¢¼
COPY ["src/", "src/"]

# æ§‹å»ºé …ç›®ï¼ˆRelease æ¨¡å¼ï¼‰
WORKDIR /src/src/ApiGateway
RUN dotnet build "ApiGateway.csproj" \
    -c Release \
    -o /app/build \
    --no-restore \
    --runtime linux-musl-x64 \
    /p:PublishTrimmed=false

# ============================================
# Stage 3: Test (å¯é¸éšæ®µ)
# ============================================
FROM build AS test
WORKDIR /src

# è¤‡è£½æ¸¬è©¦é …ç›®
COPY ["tests/ApiGateway.Tests/ApiGateway.Tests.csproj", "tests/ApiGateway.Tests/"]
COPY ["tests/", "tests/"]

# é‹è¡Œå–®å…ƒæ¸¬è©¦
RUN dotnet test "tests/ApiGateway.Tests/ApiGateway.Tests.csproj" \
    -c Release \
    --no-build \
    --verbosity normal \
    --logger "trx;LogFileName=test-results.trx"

# ============================================
# Stage 4: Publish
# ============================================
FROM build AS publish
WORKDIR /src/src/ApiGateway

# ç™¼å¸ƒæ‡‰ç”¨ï¼ˆSelf-contained, Trimmedï¼‰
RUN dotnet publish "ApiGateway.csproj" \
    -c Release \
    -o /app/publish \
    --no-restore \
    --runtime linux-musl-x64 \
    --self-contained true \
    /p:PublishTrimmed=true \
    /p:TrimMode=partial \
    /p:PublishSingleFile=false

# ============================================
# Stage 5: Runtime
# ============================================
FROM mcr.microsoft.com/dotnet/runtime-deps:8.0-alpine AS final

# å‰µå»ºé root ç”¨æˆ¶
RUN addgroup -g 1000 appgroup && \
    adduser -D -u 1000 -G appgroup appuser

WORKDIR /app

# å®‰è£é‹è¡Œæ™‚ä¾è³´
RUN apk add --no-cache \
    ca-certificates \
    tzdata \
    curl \
    && update-ca-certificates

# å¾ publish éšæ®µè¤‡è£½æ‡‰ç”¨
COPY --from=publish --chown=appuser:appgroup /app/publish .

# å‰µå»ºæ—¥èªŒç›®éŒ„
RUN mkdir -p /app/logs && \
    chown -R appuser:appgroup /app/logs

# åˆ‡æ›åˆ°é root ç”¨æˆ¶
USER appuser

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
    CMD curl -f http://localhost:5000/health || exit 1

# ç’°å¢ƒè®Šé‡
ENV ASPNETCORE_ENVIRONMENT=Production \
    ASPNETCORE_URLS=http://+:5000 \
    DOTNET_RUNNING_IN_CONTAINER=true \
    DOTNET_SYSTEM_GLOBALIZATION_INVARIANT=false

# æš´éœ²ç«¯å£
EXPOSE 5000

# å…¥å£é»
ENTRYPOINT ["./ApiGateway"]
```

**é—œéµå„ªåŒ–é»**:
1. âœ… **å¤šéšæ®µæ§‹å»º**: 5 å€‹éšæ®µ,æœ€çµ‚é¡åƒåƒ…åŒ…å«é‹è¡Œæ™‚ä¾è³´
2. âœ… **ç·©å­˜å±¤å„ªåŒ–**: å…ˆå¾©åˆ¶ `.csproj` æ–‡ä»¶,ç¨ç«‹é‚„åŸä¾è³´
3. âœ… **Self-contained ç™¼å¸ƒ**: ç„¡éœ€ .NET Runtime,é¡åƒæ›´å°
4. âœ… **Trimming**: ç§»é™¤æœªä½¿ç”¨çš„ä»£ç¢¼,æ¸›å°‘é¡åƒå¤§å°
5. âœ… **é root ç”¨æˆ¶**: å®‰å…¨æœ€ä½³å¯¦è¸
6. âœ… **å¥åº·æª¢æŸ¥**: è‡ªå‹•æª¢æ¸¬å®¹å™¨å¥åº·ç‹€æ…‹

**é¡åƒå¤§å°å°æ¯”**:
```yaml
å‚³çµ±æ§‹å»ºï¼ˆåŒ…å« SDKï¼‰: ~850 MB
å„ªåŒ–å¾Œï¼ˆAlpine + Self-containedï¼‰: ~120 MB
å„ªåŒ–ç‡: 86% â†“
```

### 2. Frontend Host Dockerfile (React + Vite)

```dockerfile
# File: packages/host/Dockerfile
# Multi-stage Build: Dependencies â†’ Build â†’ Production Server

# ============================================
# Stage 1: Dependencies
# ============================================
FROM node:20-alpine AS deps

# å®‰è£ pnpm
RUN corepack enable && corepack prepare pnpm@latest --activate

WORKDIR /app

# è¤‡è£½ä¾è³´æ¸…å–®ï¼ˆç·©å­˜å±¤å„ªåŒ–ï¼‰
COPY package.json pnpm-lock.yaml ./
COPY .npmrc ./

# å®‰è£ä¾è³´ï¼ˆåƒ…ç”Ÿç”¢ä¾è³´ï¼‰
RUN pnpm install --frozen-lockfile --prod

# ============================================
# Stage 2: Build
# ============================================
FROM node:20-alpine AS build

RUN corepack enable && corepack prepare pnpm@latest --activate

WORKDIR /app

# å¾ deps éšæ®µè¤‡è£½ node_modules
COPY --from=deps /app/node_modules ./node_modules

# è¤‡è£½æºä»£ç¢¼
COPY . .

# æ§‹å»ºæ‡‰ç”¨ï¼ˆViteï¼‰
ARG VITE_API_BASE_URL=http://localhost:5000
ARG VITE_WORKFLOW_EDITOR_URL=http://localhost:3001
ENV VITE_API_BASE_URL=$VITE_API_BASE_URL
ENV VITE_WORKFLOW_EDITOR_URL=$VITE_WORKFLOW_EDITOR_URL

RUN pnpm build

# ============================================
# Stage 3: Production Server (NGINX)
# ============================================
FROM nginx:1.25-alpine AS production

# å®‰è£é¡å¤–å·¥å…·
RUN apk add --no-cache curl

# è¤‡è£½è‡ªå®šç¾© NGINX é…ç½®
COPY nginx.conf /etc/nginx/nginx.conf
COPY default.conf /etc/nginx/conf.d/default.conf

# å¾ build éšæ®µè¤‡è£½æ§‹å»ºç”¢ç‰©
COPY --from=build /app/dist /usr/share/nginx/html

# å‰µå»ºé root ç”¨æˆ¶
RUN addgroup -g 101 -S nginx && \
    adduser -S -D -H -u 101 -h /var/cache/nginx -s /sbin/nologin -G nginx -g nginx nginx

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3000/health || exit 1

# æš´éœ²ç«¯å£
EXPOSE 3000

# å•Ÿå‹• NGINX
CMD ["nginx", "-g", "daemon off;"]
```

**NGINX é…ç½®æ–‡ä»¶**:

```nginx
# File: packages/host/nginx.conf

user nginx;
worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # æ—¥èªŒæ ¼å¼
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for"';

    access_log /var/log/nginx/access.log main;

    # æ€§èƒ½å„ªåŒ–
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzip å£“ç¸®
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml text/javascript
               application/json application/javascript application/xml+rss
               application/rss+xml font/truetype font/opentype
               application/vnd.ms-fontobject image/svg+xml;

    # å¼•å…¥ç«™é»é…ç½®
    include /etc/nginx/conf.d/*.conf;
}
```

```nginx
# File: packages/host/default.conf

server {
    listen 3000;
    server_name _;

    root /usr/share/nginx/html;
    index index.html;

    # å®‰å…¨é ­
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;
    add_header Content-Security-Policy "default-src 'self'; script-src 'self' 'unsafe-inline' 'unsafe-eval'; style-src 'self' 'unsafe-inline'; img-src 'self' data: https:; font-src 'self' data:; connect-src 'self' http://localhost:5000 http://localhost:3001 ws://localhost:3002;" always;

    # React Router SPA æ”¯æŒ
    location / {
        try_files $uri $uri/ /index.html;
    }

    # éœæ…‹è³‡æºç·©å­˜
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }

    # API ä»£ç†ï¼ˆå¯é¸ï¼‰
    location /api/ {
        proxy_pass http://api-gateway:5000/api/;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }

    # å¥åº·æª¢æŸ¥ç«¯é»
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }

    # ç¦æ­¢è¨ªå•éš±è—æ–‡ä»¶
    location ~ /\. {
        deny all;
        access_log off;
        log_not_found off;
    }
}
```

### 3. Frontend Remote Dockerfile (Vue + Webpack)

```dockerfile
# File: packages/remote/Dockerfile
# Multi-stage Build for Vue Workflow Editor

# ============================================
# Stage 1: Dependencies
# ============================================
FROM node:20-alpine AS deps

RUN corepack enable && corepack prepare pnpm@latest --activate

WORKDIR /app

COPY package.json pnpm-lock.yaml ./
COPY .npmrc ./

RUN pnpm install --frozen-lockfile --prod

# ============================================
# Stage 2: Build
# ============================================
FROM node:20-alpine AS build

RUN corepack enable && corepack prepare pnpm@latest --activate

WORKDIR /app

COPY --from=deps /app/node_modules ./node_modules
COPY . .

# æ§‹å»ºæ‡‰ç”¨ï¼ˆWebpack 5 + Module Federationï¼‰
ARG NODE_ENV=production
ARG VITE_API_BASE_URL=http://localhost:5000
ENV NODE_ENV=$NODE_ENV
ENV VITE_API_BASE_URL=$VITE_API_BASE_URL

RUN pnpm build

# ============================================
# Stage 3: Production Server
# ============================================
FROM nginx:1.25-alpine AS production

RUN apk add --no-cache curl

COPY nginx.conf /etc/nginx/nginx.conf
COPY default.conf /etc/nginx/conf.d/default.conf

# è¤‡è£½æ§‹å»ºç”¢ç‰©ï¼ˆåŒ…å« remoteEntry.jsï¼‰
COPY --from=build /app/dist /usr/share/nginx/html

HEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:3001/health || exit 1

EXPOSE 3001

CMD ["nginx", "-g", "daemon off;"]
```

**NGINX é…ç½®ï¼ˆRemoteï¼‰**:

```nginx
# File: packages/remote/default.conf

server {
    listen 3001;
    server_name _;

    root /usr/share/nginx/html;
    index index.html;

    # CORS é…ç½®ï¼ˆModule Federation éœ€è¦ï¼‰
    add_header Access-Control-Allow-Origin "*" always;
    add_header Access-Control-Allow-Methods "GET, POST, OPTIONS" always;
    add_header Access-Control-Allow-Headers "Content-Type" always;

    # remoteEntry.js ç‰¹æ®Šè™•ç†ï¼ˆModule Federation å…¥å£ï¼‰
    location /remoteEntry.js {
        add_header Access-Control-Allow-Origin "*" always;
        add_header Cache-Control "no-cache, no-store, must-revalidate";
        try_files $uri =404;
    }

    # éœæ…‹è³‡æº
    location / {
        try_files $uri $uri/ /index.html;
    }

    # å¥åº·æª¢æŸ¥
    location /health {
        access_log off;
        return 200 "healthy\n";
        add_header Content-Type text/plain;
    }
}
```

### 4. PostgreSQL Dockerfileï¼ˆè‡ªå®šç¾©æ“´å±•ï¼‰

```dockerfile
# File: infrastructure/postgres/Dockerfile
# åŸºæ–¼å®˜æ–¹é¡åƒ,æ·»åŠ è‡ªå®šç¾©æ“´å±•å’Œåˆå§‹åŒ–è…³æœ¬

FROM postgres:16-alpine

# å®‰è£ PostgreSQL æ“´å±•
RUN apk add --no-cache \
    postgresql-contrib \
    postgresql-plpython3

# è¤‡è£½åˆå§‹åŒ–è…³æœ¬
COPY init-scripts/ /docker-entrypoint-initdb.d/

# è¤‡è£½è‡ªå®šç¾©é…ç½®
COPY postgresql.conf /etc/postgresql/postgresql.conf
COPY pg_hba.conf /etc/postgresql/pg_hba.conf

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=10s --timeout=3s --start-period=30s --retries=3 \
    CMD pg_isready -U postgres || exit 1

EXPOSE 5432

CMD ["postgres", "-c", "config_file=/etc/postgresql/postgresql.conf"]
```

**PostgreSQL åˆå§‹åŒ–è…³æœ¬**:

```sql
-- File: infrastructure/postgres/init-scripts/01-init-database.sql
-- å‰µå»ºæ•¸æ“šåº«å’Œç”¨æˆ¶

-- å‰µå»ºæ‡‰ç”¨æ•¸æ“šåº«
CREATE DATABASE ai_workflow_db;

-- å‰µå»ºæ‡‰ç”¨ç”¨æˆ¶
CREATE USER ai_workflow_user WITH ENCRYPTED PASSWORD 'change_me_in_production';

-- æˆäºˆæ¬Šé™
GRANT ALL PRIVILEGES ON DATABASE ai_workflow_db TO ai_workflow_user;

-- åˆ‡æ›åˆ°æ‡‰ç”¨æ•¸æ“šåº«
\c ai_workflow_db;

-- å•Ÿç”¨æ“´å±•
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";        -- UUID ç”Ÿæˆ
CREATE EXTENSION IF NOT EXISTS "pgcrypto";         -- åŠ å¯†å‡½æ•¸
CREATE EXTENSION IF NOT EXISTS "pg_trgm";          -- æ¨¡ç³Šæœç´¢
CREATE EXTENSION IF NOT EXISTS "btree_gin";        -- GIN ç´¢å¼•å„ªåŒ–

-- å‰µå»º Schema
CREATE SCHEMA IF NOT EXISTS app;
CREATE SCHEMA IF NOT EXISTS audit;

-- æˆäºˆ Schema æ¬Šé™
GRANT ALL ON SCHEMA app TO ai_workflow_user;
GRANT ALL ON SCHEMA audit TO ai_workflow_user;

-- è¨­ç½®é»˜èªæ¬Šé™
ALTER DEFAULT PRIVILEGES IN SCHEMA app GRANT ALL ON TABLES TO ai_workflow_user;
ALTER DEFAULT PRIVILEGES IN SCHEMA app GRANT ALL ON SEQUENCES TO ai_workflow_user;
```

```sql
-- File: infrastructure/postgres/init-scripts/02-create-audit-table.sql
-- å‰µå»ºå¯©è¨ˆæ—¥èªŒè¡¨

\c ai_workflow_db;

SET search_path TO audit, public;

-- å¯©è¨ˆæ—¥èªŒè¡¨
CREATE TABLE IF NOT EXISTS audit_log (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    table_name VARCHAR(255) NOT NULL,
    operation VARCHAR(50) NOT NULL,
    old_data JSONB,
    new_data JSONB,
    changed_by VARCHAR(255),
    changed_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    ip_address INET,
    user_agent TEXT
);

CREATE INDEX idx_audit_log_table_name ON audit_log(table_name);
CREATE INDEX idx_audit_log_changed_at ON audit_log(changed_at DESC);
CREATE INDEX idx_audit_log_changed_by ON audit_log(changed_by);

-- å¯©è¨ˆè§¸ç™¼å™¨å‡½æ•¸
CREATE OR REPLACE FUNCTION audit.log_changes()
RETURNS TRIGGER AS $$
BEGIN
    IF (TG_OP = 'DELETE') THEN
        INSERT INTO audit.audit_log (table_name, operation, old_data)
        VALUES (TG_TABLE_NAME, TG_OP, row_to_json(OLD));
        RETURN OLD;
    ELSIF (TG_OP = 'UPDATE') THEN
        INSERT INTO audit.audit_log (table_name, operation, old_data, new_data)
        VALUES (TG_TABLE_NAME, TG_OP, row_to_json(OLD), row_to_json(NEW));
        RETURN NEW;
    ELSIF (TG_OP = 'INSERT') THEN
        INSERT INTO audit.audit_log (table_name, operation, new_data)
        VALUES (TG_TABLE_NAME, TG_OP, row_to_json(NEW));
        RETURN NEW;
    END IF;
    RETURN NULL;
END;
$$ LANGUAGE plpgsql;
```

**PostgreSQL é…ç½®æ–‡ä»¶**:

```conf
# File: infrastructure/postgres/postgresql.conf

# é€£æ¥è¨­ç½®
listen_addresses = '*'
port = 5432
max_connections = 200

# å…§å­˜è¨­ç½®
shared_buffers = 256MB              # 25% of RAM (1GB RAM)
effective_cache_size = 768MB        # 75% of RAM
maintenance_work_mem = 64MB
work_mem = 4MB

# WAL è¨­ç½®
wal_level = replica
max_wal_size = 1GB
min_wal_size = 80MB
checkpoint_completion_target = 0.9

# æŸ¥è©¢å„ªåŒ–
random_page_cost = 1.1              # SSD å„ªåŒ–
effective_io_concurrency = 200      # SSD ä¸¦ç™¼

# æ—¥èªŒè¨­ç½®
logging_collector = on
log_directory = 'pg_log'
log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
log_rotation_age = 1d
log_rotation_size = 100MB
log_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '
log_checkpoints = on
log_connections = on
log_disconnections = on
log_duration = off
log_lock_waits = on
log_statement = 'ddl'
log_timezone = 'UTC'

# è‡ªå‹•æ¸…ç†
autovacuum = on
autovacuum_max_workers = 3
autovacuum_naptime = 1min

# æ™‚å€
timezone = 'UTC'
```

### 5. Redis Dockerfileï¼ˆæŒä¹…åŒ–é…ç½®ï¼‰

```dockerfile
# File: infrastructure/redis/Dockerfile

FROM redis:7-alpine

# è¤‡è£½è‡ªå®šç¾©é…ç½®
COPY redis.conf /usr/local/etc/redis/redis.conf

# å‰µå»ºæ•¸æ“šç›®éŒ„
RUN mkdir -p /data && \
    chown -R redis:redis /data

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=5s --timeout=3s --start-period=10s --retries=3 \
    CMD redis-cli ping || exit 1

EXPOSE 6379

CMD ["redis-server", "/usr/local/etc/redis/redis.conf"]
```

**Redis é…ç½®æ–‡ä»¶**:

```conf
# File: infrastructure/redis/redis.conf

# ç¶²çµ¡è¨­ç½®
bind 0.0.0.0
protected-mode yes
port 6379
timeout 300
tcp-keepalive 300

# æŒä¹…åŒ–è¨­ç½®
save 900 1          # 900 ç§’å…§è‡³å°‘ 1 å€‹éµè®Šæ›´
save 300 10         # 300 ç§’å…§è‡³å°‘ 10 å€‹éµè®Šæ›´
save 60 10000       # 60 ç§’å…§è‡³å°‘ 10000 å€‹éµè®Šæ›´

# RDB æ–‡ä»¶
dbfilename dump.rdb
dir /data
rdbcompression yes
rdbchecksum yes

# AOF æŒä¹…åŒ–
appendonly yes
appendfilename "appendonly.aof"
appendfsync everysec
no-appendfsync-on-rewrite no
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb

# å…§å­˜ç®¡ç†
maxmemory 512mb
maxmemory-policy allkeys-lru
maxmemory-samples 5

# æ…¢æŸ¥è©¢æ—¥èªŒ
slowlog-log-slower-than 10000
slowlog-max-len 128

# æ—¥èªŒ
loglevel notice
logfile ""

# å®¢æˆ¶ç«¯
maxclients 10000
```

### 6. RabbitMQ Dockerfile

```dockerfile
# File: infrastructure/rabbitmq/Dockerfile

FROM rabbitmq:3.12-management-alpine

# å®‰è£æ’ä»¶
RUN rabbitmq-plugins enable --offline \
    rabbitmq_management \
    rabbitmq_prometheus \
    rabbitmq_shovel \
    rabbitmq_shovel_management

# è¤‡è£½é…ç½®æ–‡ä»¶
COPY rabbitmq.conf /etc/rabbitmq/rabbitmq.conf
COPY definitions.json /etc/rabbitmq/definitions.json

# å¥åº·æª¢æŸ¥
HEALTHCHECK --interval=10s --timeout=5s --start-period=30s --retries=3 \
    CMD rabbitmq-diagnostics -q ping || exit 1

EXPOSE 5672 15672

CMD ["rabbitmq-server"]
```

**RabbitMQ é…ç½®**:

```conf
# File: infrastructure/rabbitmq/rabbitmq.conf

# ç¶²çµ¡è¨­ç½®
listeners.tcp.default = 5672
management.tcp.port = 15672

# æ—¥èªŒ
log.console = true
log.console.level = info

# å…§å­˜å’Œç£ç›¤é™åˆ¶
vm_memory_high_watermark.relative = 0.6
disk_free_limit.absolute = 2GB

# é»˜èªç”¨æˆ¶ï¼ˆåƒ…é–‹ç™¼ç’°å¢ƒï¼‰
default_user = admin
default_pass = admin_change_me

# Management æ’ä»¶
management.load_definitions = /etc/rabbitmq/definitions.json
```

```json
// File: infrastructure/rabbitmq/definitions.json
{
  "rabbit_version": "3.12.0",
  "rabbitmq_version": "3.12.0",
  "users": [
    {
      "name": "admin",
      "password_hash": "...",
      "hashing_algorithm": "rabbit_password_hashing_sha256",
      "tags": "administrator"
    },
    {
      "name": "app_user",
      "password_hash": "...",
      "hashing_algorithm": "rabbit_password_hashing_sha256",
      "tags": ""
    }
  ],
  "vhosts": [
    { "name": "/" },
    { "name": "ai-workflow" }
  ],
  "permissions": [
    {
      "user": "app_user",
      "vhost": "ai-workflow",
      "configure": ".*",
      "write": ".*",
      "read": ".*"
    }
  ],
  "exchanges": [
    {
      "name": "workflow.events",
      "vhost": "ai-workflow",
      "type": "topic",
      "durable": true,
      "auto_delete": false
    }
  ],
  "queues": [
    {
      "name": "workflow.execution",
      "vhost": "ai-workflow",
      "durable": true,
      "auto_delete": false,
      "arguments": {
        "x-message-ttl": 86400000,
        "x-max-length": 10000
      }
    }
  ],
  "bindings": [
    {
      "source": "workflow.events",
      "vhost": "ai-workflow",
      "destination": "workflow.execution",
      "destination_type": "queue",
      "routing_key": "workflow.#"
    }
  ]
}
```

---

## ğŸ³ Docker Compose å®Œæ•´é…ç½®

### é–‹ç™¼ç’°å¢ƒ Docker Compose

```yaml
# File: docker-compose.yml
# é–‹ç™¼ç’°å¢ƒå®Œæ•´é…ç½®

version: '3.9'

# ============================================
# Networks
# ============================================
networks:
  ai-workflow-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16

# ============================================
# Volumes
# ============================================
volumes:
  postgres-data:
    driver: local
  redis-data:
    driver: local
  rabbitmq-data:
    driver: local
  nginx-certs:
    driver: local
  app-logs:
    driver: local

# ============================================
# Services
# ============================================
services:
  # ------------------------------------------
  # Database Layer
  # ------------------------------------------
  postgres:
    build:
      context: ./infrastructure/postgres
      dockerfile: Dockerfile
    container_name: ai-workflow-postgres
    hostname: postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: ai_workflow_db
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres_dev_password}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
      PGDATA: /var/lib/postgresql/data/pgdata
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./infrastructure/postgres/init-scripts:/docker-entrypoint-initdb.d:ro
      - app-logs:/var/log/postgresql
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.10
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  redis:
    build:
      context: ./infrastructure/redis
      dockerfile: Dockerfile
    container_name: ai-workflow-redis
    hostname: redis
    restart: unless-stopped
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.11
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  rabbitmq:
    build:
      context: ./infrastructure/rabbitmq
      dockerfile: Dockerfile
    container_name: ai-workflow-rabbitmq
    hostname: rabbitmq
    restart: unless-stopped
    environment:
      RABBITMQ_DEFAULT_USER: admin
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD:-admin_dev_password}
    ports:
      - "5672:5672"    # AMQP
      - "15672:15672"  # Management UI
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.12
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "-q", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # ------------------------------------------
  # Backend Services
  # ------------------------------------------
  api-gateway:
    build:
      context: ./src/ApiGateway
      dockerfile: Dockerfile
      target: final
    container_name: ai-workflow-api-gateway
    hostname: api-gateway
    restart: unless-stopped
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      ASPNETCORE_URLS: http://+:5000
      ConnectionStrings__DefaultConnection: "Host=postgres;Port=5432;Database=ai_workflow_db;Username=postgres;Password=${POSTGRES_PASSWORD:-postgres_dev_password}"
      Redis__ConnectionString: "redis:6379,abortConnect=false"
      RabbitMQ__HostName: rabbitmq
      RabbitMQ__UserName: admin
      RabbitMQ__Password: ${RABBITMQ_PASSWORD:-admin_dev_password}
      Logging__LogLevel__Default: Information
      Logging__LogLevel__Microsoft: Warning
    ports:
      - "5000:5000"
    volumes:
      - app-logs:/app/logs
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.20
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 3s
      retries: 3
      start_period: 40s

  agent-service:
    build:
      context: ./src/AgentService
      dockerfile: Dockerfile
      target: final
    container_name: ai-workflow-agent-service
    hostname: agent-service
    restart: unless-stopped
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      ASPNETCORE_URLS: http://+:5001
      ConnectionStrings__DefaultConnection: "Host=postgres;Port=5432;Database=ai_workflow_db;Username=postgres;Password=${POSTGRES_PASSWORD:-postgres_dev_password}"
      Redis__ConnectionString: "redis:6379"
      RabbitMQ__HostName: rabbitmq
      SemanticKernel__AzureOpenAI__Endpoint: ${AZURE_OPENAI_ENDPOINT}
      SemanticKernel__AzureOpenAI__ApiKey: ${AZURE_OPENAI_API_KEY}
      SemanticKernel__AzureOpenAI__DeploymentName: ${AZURE_OPENAI_DEPLOYMENT_NAME:-gpt-4}
    ports:
      - "5001:5001"
    volumes:
      - app-logs:/app/logs
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.21
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy

  workflow-service:
    build:
      context: ./src/WorkflowService
      dockerfile: Dockerfile
      target: final
    container_name: ai-workflow-workflow-service
    hostname: workflow-service
    restart: unless-stopped
    environment:
      ASPNETCORE_ENVIRONMENT: Development
      ASPNETCORE_URLS: http://+:5002
      ConnectionStrings__DefaultConnection: "Host=postgres;Port=5432;Database=ai_workflow_db;Username=postgres;Password=${POSTGRES_PASSWORD:-postgres_dev_password}"
      Redis__ConnectionString: "redis:6379"
      RabbitMQ__HostName: rabbitmq
    ports:
      - "5002:5002"
    volumes:
      - app-logs:/app/logs
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.22
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  # ------------------------------------------
  # Frontend Services
  # ------------------------------------------
  frontend-host:
    build:
      context: ./packages/host
      dockerfile: Dockerfile
      target: production
      args:
        VITE_API_BASE_URL: http://localhost:5000
        VITE_WORKFLOW_EDITOR_URL: http://localhost:3001
    container_name: ai-workflow-frontend-host
    hostname: frontend-host
    restart: unless-stopped
    ports:
      - "3000:3000"
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.30
    depends_on:
      - api-gateway
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 3s
      retries: 3

  frontend-remote:
    build:
      context: ./packages/remote
      dockerfile: Dockerfile
      target: production
      args:
        VITE_API_BASE_URL: http://localhost:5000
    container_name: ai-workflow-frontend-remote
    hostname: frontend-remote
    restart: unless-stopped
    ports:
      - "3001:3001"
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.31
    depends_on:
      - api-gateway
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 3s
      retries: 3

  # ------------------------------------------
  # WebSocket Server (å”ä½œ)
  # ------------------------------------------
  websocket-server:
    build:
      context: ./services/websocket-server
      dockerfile: Dockerfile
    container_name: ai-workflow-websocket-server
    hostname: websocket-server
    restart: unless-stopped
    environment:
      NODE_ENV: development
      PORT: 3002
      REDIS_URL: redis://redis:6379
    ports:
      - "3002:3002"
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.32
    depends_on:
      redis:
        condition: service_healthy

  # ------------------------------------------
  # Reverse Proxy (NGINX)
  # ------------------------------------------
  nginx:
    image: nginx:1.25-alpine
    container_name: ai-workflow-nginx
    hostname: nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infrastructure/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./infrastructure/nginx/conf.d:/etc/nginx/conf.d:ro
      - nginx-certs:/etc/nginx/certs:ro
      - app-logs:/var/log/nginx
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.40
    depends_on:
      - api-gateway
      - frontend-host
      - frontend-remote
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 3s
      retries: 3

  # ------------------------------------------
  # Monitoring (Prometheus + Grafana)
  # ------------------------------------------
  prometheus:
    image: prom/prometheus:latest
    container_name: ai-workflow-prometheus
    hostname: prometheus
    restart: unless-stopped
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    ports:
      - "9090:9090"
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.50

  grafana:
    image: grafana/grafana:latest
    container_name: ai-workflow-grafana
    hostname: grafana
    restart: unless-stopped
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
      GF_INSTALL_PLUGINS: grafana-piechart-panel
    ports:
      - "3100:3000"
    volumes:
      - ./infrastructure/grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana-data:/var/lib/grafana
    networks:
      ai-workflow-network:
        ipv4_address: 172.28.0.51
    depends_on:
      - prometheus
```

### ç”Ÿç”¢ç’°å¢ƒ Docker Compose

```yaml
# File: docker-compose.prod.yml
# ç”Ÿç”¢ç’°å¢ƒé…ç½®ï¼ˆç°¡åŒ–ç‰ˆï¼Œå¯¦éš›ç”Ÿç”¢ä½¿ç”¨ Kubernetesï¼‰

version: '3.9'

# ç¹¼æ‰¿é–‹ç™¼ç’°å¢ƒé…ç½®
include:
  - docker-compose.yml

services:
  # è¦†è“‹é–‹ç™¼ç’°å¢ƒè¨­ç½®
  api-gateway:
    environment:
      ASPNETCORE_ENVIRONMENT: Production
      Logging__LogLevel__Default: Warning
      Logging__LogLevel__Microsoft: Error
    deploy:
      replicas: 3
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M

  postgres:
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G

  redis:
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
```

---

## ğŸ” å®¹å™¨å®‰å…¨æœ€ä½³å¯¦è¸

### 1. é Root ç”¨æˆ¶åŸ·è¡Œ

**æ‰€æœ‰æ‡‰ç”¨å®¹å™¨**å¿…é ˆä½¿ç”¨é root ç”¨æˆ¶é‹è¡Œï¼š

```dockerfile
# âŒ éŒ¯èª¤ï¼šä»¥ root ç”¨æˆ¶é‹è¡Œ
USER root

# âœ… æ­£ç¢ºï¼šå‰µå»ºä¸¦ä½¿ç”¨é root ç”¨æˆ¶
RUN addgroup -g 1000 appgroup && \
    adduser -D -u 1000 -G appgroup appuser

USER appuser
```

### 2. æœ€å°åŒ–é¡åƒæ”»æ“Šé¢

```dockerfile
# âœ… ä½¿ç”¨ Alpine åŸºç¤é¡åƒï¼ˆæœ€å°åŒ–ï¼‰
FROM node:20-alpine AS build

# âœ… ç§»é™¤ä¸å¿…è¦çš„åŒ…
RUN apk del build-dependencies && \
    rm -rf /var/cache/apk/*

# âœ… Multi-stage build ç§»é™¤æ§‹å»ºå·¥å…·
FROM alpine:latest AS final
COPY --from=build /app/dist /app
```

### 3. æƒææ¼æ´

```bash
# ä½¿ç”¨ Trivy æƒæé¡åƒæ¼æ´
docker run --rm -v /var/run/docker.sock:/var/run/docker.sock \
  aquasec/trivy image ai-workflow/api-gateway:latest

# ä½¿ç”¨ Snyk æƒæ
snyk container test ai-workflow/api-gateway:latest

# é›†æˆåˆ° CI/CD
# .github/workflows/security-scan.yml
- name: Run Trivy vulnerability scanner
  uses: aquasecurity/trivy-action@master
  with:
    image-ref: 'ai-workflow/api-gateway:${{ github.sha }}'
    format: 'sarif'
    output: 'trivy-results.sarif'
```

### 4. å¯†é‘°ç®¡ç†

```yaml
# âŒ éŒ¯èª¤ï¼šç¡¬ç·¨ç¢¼å¯†ç¢¼
environment:
  POSTGRES_PASSWORD: "my_secret_password"

# âœ… æ­£ç¢ºï¼šä½¿ç”¨ç’°å¢ƒè®Šé‡
environment:
  POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}

# âœ… æ­£ç¢ºï¼šä½¿ç”¨ Docker Secretsï¼ˆSwarm/Kubernetesï¼‰
secrets:
  - postgres_password

secrets:
  postgres_password:
    file: ./secrets/postgres_password.txt
```

### 5. ç¶²çµ¡éš”é›¢

```yaml
# âœ… åˆ†é›¢å‰ç«¯å’Œå¾Œç«¯ç¶²çµ¡
networks:
  frontend-network:
    driver: bridge
  backend-network:
    driver: bridge
    internal: true  # ç¦æ­¢å¤–éƒ¨è¨ªå•

services:
  api-gateway:
    networks:
      - frontend-network
      - backend-network

  postgres:
    networks:
      - backend-network  # åƒ…å…§éƒ¨ç¶²çµ¡è¨ªå•
```

### 6. åªè®€æ–‡ä»¶ç³»çµ±

```yaml
services:
  api-gateway:
    read_only: true  # æ–‡ä»¶ç³»çµ±åªè®€
    tmpfs:
      - /tmp          # è‡¨æ™‚æ–‡ä»¶ç³»çµ±
      - /app/logs     # æ—¥èªŒç›®éŒ„
```

### 7. è³‡æºé™åˆ¶

```yaml
services:
  api-gateway:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
    ulimits:
      nofile:
        soft: 65536
        hard: 65536
```

---

## ğŸ“Š å®¹å™¨ç›£æ§å’Œæ—¥èªŒ

### Prometheus é…ç½®

```yaml
# File: infrastructure/prometheus/prometheus.yml

global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  # .NET æ‡‰ç”¨ (Prometheus Exporter)
  - job_name: 'dotnet-api'
    static_configs:
      - targets:
          - 'api-gateway:5000'
          - 'agent-service:5001'
          - 'workflow-service:5002'
    metrics_path: '/metrics'

  # Node.js æ‡‰ç”¨
  - job_name: 'nodejs-websocket'
    static_configs:
      - targets:
          - 'websocket-server:3002'
    metrics_path: '/metrics'

  # PostgreSQL Exporter
  - job_name: 'postgres'
    static_configs:
      - targets:
          - 'postgres-exporter:9187'

  # Redis Exporter
  - job_name: 'redis'
    static_configs:
      - targets:
          - 'redis-exporter:9121'

  # RabbitMQ
  - job_name: 'rabbitmq'
    static_configs:
      - targets:
          - 'rabbitmq:15692'
    metrics_path: '/metrics'

  # Docker å®¹å™¨
  - job_name: 'docker'
    static_configs:
      - targets:
          - 'cadvisor:8080'
```

### Grafana Dashboards

```yaml
# File: infrastructure/grafana/provisioning/dashboards/dashboard.yml

apiVersion: 1

providers:
  - name: 'default'
    orgId: 1
    folder: ''
    type: file
    disableDeletion: false
    updateIntervalSeconds: 10
    allowUiUpdates: true
    options:
      path: /etc/grafana/provisioning/dashboards
```

### æ—¥èªŒæ”¶é›†ï¼ˆFluentdï¼‰

```yaml
# File: infrastructure/fluentd/fluent.conf

<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<filter docker.**>
  @type parser
  key_name log
  <parse>
    @type json
  </parse>
</filter>

<match docker.**>
  @type elasticsearch
  host elasticsearch
  port 9200
  logstash_format true
  logstash_prefix docker
  <buffer>
    flush_interval 10s
  </buffer>
</match>
```

---

## ğŸš€ éƒ¨ç½²å‘½ä»¤

### é–‹ç™¼ç’°å¢ƒå•Ÿå‹•

```bash
# 1. å‰µå»º .env æ–‡ä»¶
cat > .env << 'EOF'
POSTGRES_PASSWORD=postgres_dev_password
RABBITMQ_PASSWORD=admin_dev_password
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_API_KEY=your_api_key_here
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4
GRAFANA_PASSWORD=admin
EOF

# 2. æ§‹å»ºæ‰€æœ‰é¡åƒ
docker-compose build --parallel

# 3. å•Ÿå‹•æ‰€æœ‰æœå‹™
docker-compose up -d

# 4. æŸ¥çœ‹æœå‹™ç‹€æ…‹
docker-compose ps

# 5. æŸ¥çœ‹æ—¥èªŒ
docker-compose logs -f api-gateway

# 6. åœæ­¢æ‰€æœ‰æœå‹™
docker-compose down

# 7. åœæ­¢ä¸¦åˆªé™¤æ‰€æœ‰æ•¸æ“š
docker-compose down -v
```

### å–®ç¨æ§‹å»ºå’Œé‹è¡Œ

```bash
# æ§‹å»ºå–®å€‹æœå‹™
docker-compose build api-gateway

# åƒ…å•Ÿå‹•å¾Œç«¯æœå‹™
docker-compose up -d postgres redis rabbitmq api-gateway

# é‡å•Ÿæœå‹™
docker-compose restart api-gateway

# æŸ¥çœ‹è³‡æºä½¿ç”¨
docker stats
```

### ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²

```bash
# ä½¿ç”¨ç”Ÿç”¢é…ç½®
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d

# æ“´å±•æœå‹™
docker-compose up -d --scale api-gateway=3 --scale agent-service=2
```

---

## ğŸ”§ æ•…éšœæ’æŸ¥

### å¸¸è¦‹å•é¡Œ

**Q1: å®¹å™¨å•Ÿå‹•å¤±æ•—ï¼Œå¥åº·æª¢æŸ¥ä¸€ç›´å¤±æ•—?**

```bash
# æª¢æŸ¥å®¹å™¨æ—¥èªŒ
docker logs ai-workflow-api-gateway

# é€²å…¥å®¹å™¨èª¿è©¦
docker exec -it ai-workflow-api-gateway sh

# æ‰‹å‹•åŸ·è¡Œå¥åº·æª¢æŸ¥
curl -f http://localhost:5000/health
```

**Q2: æ•¸æ“šåº«é€£æ¥å¤±æ•—?**

```bash
# æª¢æŸ¥ PostgreSQL æ˜¯å¦å°±ç·’
docker exec -it ai-workflow-postgres pg_isready -U postgres

# æ¸¬è©¦é€£æ¥
docker exec -it ai-workflow-postgres psql -U postgres -d ai_workflow_db -c "SELECT 1;"

# æª¢æŸ¥ç¶²çµ¡é€£æ¥
docker exec -it ai-workflow-api-gateway ping postgres
```

**Q3: å‰ç«¯ç„¡æ³•è¨ªå•å¾Œç«¯ API?**

```bash
# æª¢æŸ¥ NGINX é…ç½®
docker exec -it ai-workflow-nginx nginx -t

# æŸ¥çœ‹ NGINX æ—¥èªŒ
docker logs ai-workflow-nginx

# æ¸¬è©¦ API é€£æ¥
curl http://localhost:80/api/health
```

**Q4: å®¹å™¨ä½”ç”¨éå¤šè³‡æº?**

```bash
# æŸ¥çœ‹è³‡æºä½¿ç”¨
docker stats --no-stream

# é™åˆ¶è³‡æº
docker update --cpus="0.5" --memory="256m" ai-workflow-api-gateway

# æ¸…ç†æœªä½¿ç”¨çš„è³‡æº
docker system prune -a --volumes
```

---

## ğŸ“š åƒè€ƒè³‡æ–™

### å®˜æ–¹æ–‡æª”
- [Docker Best Practices](https://docs.docker.com/develop/dev-best-practices/)
- [Dockerfile Reference](https://docs.docker.com/engine/reference/builder/)
- [Docker Compose Specification](https://docs.docker.com/compose/compose-file/)
- [Multi-stage Builds](https://docs.docker.com/build/building/multi-stage/)

### å®‰å…¨æŒ‡å—
- [Docker Security Best Practices](https://docs.docker.com/engine/security/)
- [CIS Docker Benchmark](https://www.cisecurity.org/benchmark/docker)
- [OWASP Container Security](https://owasp.org/www-project-docker-top-10/)

### å„ªåŒ–è³‡æº
- [Alpine Linux](https://alpinelinux.org/)
- [Dive - Image Size Analyzer](https://github.com/wagoodman/dive)
- [Hadolint - Dockerfile Linter](https://github.com/hadolint/hadolint)

---

**æ–‡æª”ç¶­è­·**: DevOps åœ˜éšŠ
**æœ€å¾Œæ›´æ–°**: 2025-11-01
**ç‰ˆæœ¬**: 1.0.0
**ç‹€æ…‹**: âœ… å®Œæ•´
