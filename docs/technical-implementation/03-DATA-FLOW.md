# TID Part 1.3: æ•¸æ“šæµè¨­è¨ˆ (Data Flow Design)

**æ–‡æª”ç‰ˆæœ¬**: v1.0.0
**å‰µå»ºæ—¥æœŸ**: 2025-10-30
**ç‹€æ…‹**: âœ… å®Œæˆ
**æ‰€å±¬**: Part 1 - System Architecture Design

---

## ç›®éŒ„

1. [æ•¸æ“šæµæ¶æ§‹æ¦‚è¦½](#1-æ•¸æ“šæµæ¶æ§‹æ¦‚è¦½)
2. [åŒæ­¥æ•¸æ“šæµ](#2-åŒæ­¥æ•¸æ“šæµ)
3. [ç•°æ­¥æ•¸æ“šæµ](#3-ç•°æ­¥æ•¸æ“šæµ)
4. [å¯¦æ™‚æ•¸æ“šæµ](#4-å¯¦æ™‚æ•¸æ“šæµ)
5. [ç‹€æ…‹ç®¡ç†ç­–ç•¥](#5-ç‹€æ…‹ç®¡ç†ç­–ç•¥)
6. [æ•¸æ“šä¸€è‡´æ€§æ¨¡å¼](#6-æ•¸æ“šä¸€è‡´æ€§æ¨¡å¼)
7. [äº‹å‹™ç®¡ç†](#7-äº‹å‹™ç®¡ç†)
8. [æ•¸æ“šæµç›£æ§](#8-æ•¸æ“šæµç›£æ§)

---

## 1. æ•¸æ“šæµæ¶æ§‹æ¦‚è¦½

### 1.1 æ•´é«”æ•¸æ“šæµåœ–

```mermaid
graph TB
    subgraph "å‰ç«¯å±¤"
        UI[Web UI / Mobile]
    end

    subgraph "API Gateway Layer"
        Gateway[API Gateway]
        Cache[Redis Cache]
    end

    subgraph "åŒæ­¥æµ (Synchronous)"
        AgentSvc[Agent Service]
        PersonaSvc[Persona Service]
        SQLSvc[Text-to-SQL]
    end

    subgraph "ç•°æ­¥æµ (Asynchronous)"
        Queue[RabbitMQ]
        AgentWorker[Agent Executor]
        CodeWorker[Code Executor]
        RAGWorker[RAG Indexer]
    end

    subgraph "å¯¦æ™‚æµ (Real-time)"
        WorkflowWS[Workflow WebSocket]
        CRDT[Y.js CRDT State]
    end

    subgraph "æ•¸æ“šå±¤"
        PostgreSQL[(PostgreSQL)]
        AzureSearch[(Azure AI Search)]
        Redis[(Redis)]
    end

    UI -->|HTTP Request| Gateway
    Gateway -->|Query| Cache
    Gateway -->|REST API| AgentSvc
    Gateway -->|REST API| PersonaSvc
    Gateway -->|REST API| SQLSvc

    AgentSvc -->|Publish Task| Queue
    Queue -->|Consume| AgentWorker
    Queue -->|Consume| CodeWorker
    Queue -->|Consume| RAGWorker

    UI -->|WebSocket| WorkflowWS
    WorkflowWS <-->|CRDT Sync| CRDT

    AgentSvc -->|Read/Write| PostgreSQL
    PersonaSvc -->|Read/Write| PostgreSQL
    RAGWorker -->|Index| AzureSearch
    WorkflowWS -->|Persist| PostgreSQL

    AgentWorker -->|Update Status| PostgreSQL
    CodeWorker -->|Store Results| PostgreSQL
```

### 1.2 ä¸‰ç¨®æ•¸æ“šæµé¡å‹

| é¡å‹ | ç”¨é€” | é€šä¿¡å”è­° | å»¶é² | å¯é æ€§ä¿è­‰ |
|------|------|----------|------|-----------|
| **åŒæ­¥æµ** | å³æ™‚æŸ¥è©¢ã€ç°¡å–®æ“ä½œ | HTTP/REST | <100ms | å¼·ä¸€è‡´æ€§ |
| **ç•°æ­¥æµ** | é•·æ™‚é–“ä»»å‹™ã€å¾Œå°è™•ç† | Message Queue | ç§’ç´š | æœ€çµ‚ä¸€è‡´æ€§ |
| **å¯¦æ™‚æµ** | å”ä½œç·¨è¼¯ã€å³æ™‚æ›´æ–° | WebSocket | <50ms | å› æœä¸€è‡´æ€§ |

### 1.3 æ•¸æ“šæµè¨­è¨ˆåŸå‰‡

1. **è®€å¯«åˆ†é›¢**: æŸ¥è©¢èµ°åŒæ­¥æµï¼Œå¯«æ“ä½œè€ƒæ…®ç•°æ­¥æµ
2. **ç·©å­˜å„ªå…ˆ**: é«˜é »è®€å–æ•¸æ“šä½¿ç”¨ Redis ç·©å­˜
3. **ç•°æ­¥è§£è€¦**: é•·æ™‚é–“ä»»å‹™ä½¿ç”¨æ¶ˆæ¯éšŠåˆ—è§£è€¦
4. **å¯¦æ™‚å„ªåŒ–**: å”ä½œå ´æ™¯ä½¿ç”¨ WebSocket + CRDT
5. **å†ªç­‰è¨­è¨ˆ**: æ‰€æœ‰ç•°æ­¥æ“ä½œæ”¯æŒé‡è©¦å’Œå†ªç­‰æ€§

---

## 2. åŒæ­¥æ•¸æ“šæµ

### 2.1 å…¸å‹è«‹æ±‚-éŸ¿æ‡‰æµç¨‹

#### Scenario 1: å‰µå»º AI Agent

```mermaid
sequenceDiagram
    participant UI as Web UI
    participant GW as API Gateway
    participant Auth as Auth Service
    participant Agent as Agent Service
    participant Persona as Persona Service
    participant DB as PostgreSQL
    participant Cache as Redis

    UI->>GW: POST /api/v1/agents
    GW->>Auth: Validate JWT Token
    Auth-->>GW: Token Valid

    GW->>Agent: Create Agent Request
    Agent->>Persona: GET /personas/{id}
    Persona->>Cache: Check Cache
    alt Cache Hit
        Cache-->>Persona: Cached Persona
    else Cache Miss
        Persona->>DB: Query Persona
        DB-->>Persona: Persona Data
        Persona->>Cache: Store in Cache (TTL: 1h)
    end
    Persona-->>Agent: Persona Details

    Agent->>DB: INSERT INTO agents
    DB-->>Agent: Agent Created
    Agent->>Cache: Invalidate Agent List Cache
    Agent-->>GW: 201 Created
    GW-->>UI: Agent Response
```

**é—œéµé»**:
- JWT èªè­‰åœ¨ API Gateway å±¤
- Persona æ•¸æ“šä½¿ç”¨ Redis ç·©å­˜ (TTL: 1å°æ™‚)
- å¯«æ“ä½œå¾Œä¸»å‹•å¤±æ•ˆç›¸é—œç·©å­˜
- å®Œæ•´æµç¨‹ < 100ms (cache hit)

#### Scenario 2: Text-to-SQL æŸ¥è©¢

```mermaid
sequenceDiagram
    participant UI as Web UI
    participant GW as API Gateway
    participant SQL as Text-to-SQL Service
    participant OpenAI as Azure OpenAI
    participant Cache as Redis
    participant PG as PostgreSQL (User DB)

    UI->>GW: POST /api/v1/text-to-sql/query
    GW->>SQL: Natural Language Query

    SQL->>Cache: Check Schema Cache
    alt Schema Cached
        Cache-->>SQL: Schema Metadata
    else Schema Not Cached
        SQL->>PG: Query Information Schema
        PG-->>SQL: Schema Data
        SQL->>Cache: Store Schema (TTL: 24h)
    end

    SQL->>SQL: Validate Query Safety
    SQL->>OpenAI: Generate SQL (GPT-4)
    OpenAI-->>SQL: Generated SQL

    SQL->>SQL: Multi-layer Validation
    alt Validation Failed
        SQL-->>UI: 400 Bad Request
    else Validation Passed
        SQL->>PG: Execute READ-ONLY SQL
        PG-->>SQL: Query Results
        SQL-->>GW: Results + Generated SQL
        GW-->>UI: JSON Response
    end
```

**å®‰å…¨æªæ–½**:
- Schema ç·©å­˜ 24 å°æ™‚æ¸›å°‘ DB æŸ¥è©¢
- å¤šå±¤ SQL é©—è­‰ (14 keywords + 10 patterns)
- READ-ONLY transaction
- åŸ·è¡Œè¶…æ™‚é™åˆ¶ (30 ç§’)

### 2.2 ç·©å­˜ç­–ç•¥

#### 2.2.1 Cache-Aside Pattern

```csharp
public async Task<Persona> GetPersonaAsync(Guid personaId)
{
    // 1. Check cache first
    var cacheKey = $"persona:{personaId}";
    var cached = await _cache.GetStringAsync(cacheKey);

    if (cached != null)
    {
        _logger.LogInformation("Cache hit for {PersonaId}", personaId);
        return JsonSerializer.Deserialize<Persona>(cached);
    }

    // 2. Cache miss â†’ Query database
    _logger.LogInformation("Cache miss for {PersonaId}", personaId);
    var persona = await _repository.GetByIdAsync(personaId);

    if (persona == null)
        throw new NotFoundException($"Persona {personaId} not found");

    // 3. Store in cache (TTL: 1 hour)
    await _cache.SetStringAsync(
        cacheKey,
        JsonSerializer.Serialize(persona),
        new DistributedCacheEntryOptions
        {
            AbsoluteExpirationRelativeToNow = TimeSpan.FromHours(1)
        }
    );

    return persona;
}
```

#### 2.2.2 Cache Invalidation

```csharp
public async Task UpdatePersonaAsync(Guid personaId, UpdatePersonaRequest request)
{
    // 1. Update database
    var persona = await _repository.GetByIdAsync(personaId);
    persona.Name = request.Name;
    persona.Template = request.Template;
    persona.UpdatedAt = DateTime.UtcNow;

    await _repository.UpdateAsync(persona);

    // 2. Invalidate cache
    await _cache.RemoveAsync($"persona:{personaId}");

    // 3. Invalidate list cache (if exists)
    await _cache.RemoveAsync($"persona:list:{persona.UserId}");

    _logger.LogInformation("Invalidated cache for {PersonaId}", personaId);
}
```

#### 2.2.3 ç·©å­˜ç­–ç•¥ç¸½çµ

| æ•¸æ“šé¡å‹ | TTL | Invalidation ç­–ç•¥ |
|---------|-----|------------------|
| Persona Templates | 1 å°æ™‚ | æ›´æ–°æ™‚ä¸»å‹•å¤±æ•ˆ |
| Agent Metadata | 30 åˆ†é˜ | æ›´æ–°æ™‚ä¸»å‹•å¤±æ•ˆ |
| Database Schema | 24 å°æ™‚ | DDL è®Šæ›´æ™‚å¤±æ•ˆ |
| User Sessions | 15 åˆ†é˜ | ç™»å‡ºæ™‚å¤±æ•ˆ |
| Query Results (SQL) | 5 åˆ†é˜ | å¯«æ“ä½œæ™‚å¤±æ•ˆ |

---

## 3. ç•°æ­¥æ•¸æ“šæµ

### 3.1 æ¶ˆæ¯éšŠåˆ—æ¶æ§‹

```mermaid
graph LR
    subgraph "Producers"
        AgentAPI[Agent API]
        CodeAPI[Code Sandbox API]
        RAGAPI[RAG API]
    end

    subgraph "RabbitMQ Exchanges"
        DirectEx[Direct Exchange]
        TopicEx[Topic Exchange]
        FanoutEx[Fanout Exchange]
    end

    subgraph "Queues"
        AgentQueue[agent.execute]
        CodeQueue[code.execute]
        RAGQueue[rag.index]
        NotifyQueue[notifications]
    end

    subgraph "Consumers"
        AgentWorker[Agent Executor]
        CodeWorker[Code Executor]
        RAGWorker[RAG Indexer]
        NotifyWorker[Notification Worker]
    end

    AgentAPI -->|agent.execute| DirectEx
    CodeAPI -->|code.execute| DirectEx
    RAGAPI -->|rag.index| TopicEx

    DirectEx --> AgentQueue
    DirectEx --> CodeQueue
    TopicEx --> RAGQueue

    AgentQueue --> AgentWorker
    CodeQueue --> CodeWorker
    RAGQueue --> RAGWorker

    AgentWorker -->|task.completed| FanoutEx
    FanoutEx --> NotifyQueue
    NotifyQueue --> NotifyWorker
```

### 3.2 å…¸å‹ç•°æ­¥æµç¨‹

#### Scenario 3: Agent åŸ·è¡Œä»»å‹™

```mermaid
sequenceDiagram
    participant UI as Web UI
    participant API as Agent API
    participant Queue as RabbitMQ
    participant Worker as Agent Executor
    participant CodeSvc as Code Sandbox
    participant DB as PostgreSQL
    participant Cache as Redis

    UI->>API: POST /agents/{id}/execute
    API->>DB: Create Execution Record (Status: Pending)
    DB-->>API: execution_id

    API->>Queue: Publish agent.execute
    API-->>UI: 202 Accepted {execution_id}

    Note over UI: User can poll status

    Queue->>Worker: Consume Message
    Worker->>DB: Update Status â†’ Running
    Worker->>Cache: Set Status Cache (execution_id: Running)

    Worker->>Worker: Execute Agent Logic
    alt Needs Code Execution
        Worker->>CodeSvc: Execute Code
        CodeSvc-->>Worker: Execution Results
    end

    alt Success
        Worker->>DB: Update Status â†’ Completed
        Worker->>Cache: Set Result Cache (TTL: 1h)
        Worker->>Queue: Publish task.completed
    else Failure
        Worker->>DB: Update Status â†’ Failed
        Worker->>Cache: Set Error Cache
        Worker->>Queue: Publish task.failed
    end

    UI->>API: GET /executions/{execution_id}
    API->>Cache: Check Status Cache
    Cache-->>API: Status + Results
    API-->>UI: Execution Details
```

**é—œéµè¨­è¨ˆ**:
- **ç•°æ­¥éŸ¿æ‡‰**: API ç«‹å³è¿”å› 202 Accepted
- **ç‹€æ…‹è¿½è¹¤**: Database + Redis é›™é‡ç‹€æ…‹å­˜å„²
- **è¼ªè©¢å„ªåŒ–**: Redis ç·©å­˜æ¸›å°‘ DB æŸ¥è©¢å£“åŠ›
- **éŒ¯èª¤è™•ç†**: å¤±æ•—æ¶ˆæ¯é‡è©¦æ©Ÿåˆ¶ (Max 3 æ¬¡)

### 3.3 æ¶ˆæ¯æ ¼å¼å®šç¾©

#### Agent Execution Message

```json
{
  "message_id": "uuid",
  "correlation_id": "uuid",
  "timestamp": "2025-10-30T10:15:30Z",
  "routing_key": "agent.execute",
  "payload": {
    "execution_id": "uuid",
    "agent_id": "uuid",
    "user_id": "uuid",
    "input": {
      "query": "Analyze this data",
      "context": {}
    },
    "config": {
      "timeout_seconds": 300,
      "max_tokens": 4000,
      "temperature": 0.7
    }
  },
  "metadata": {
    "retry_count": 0,
    "max_retries": 3,
    "priority": "normal"
  }
}
```

#### Task Completed Event

```json
{
  "message_id": "uuid",
  "correlation_id": "uuid",
  "timestamp": "2025-10-30T10:20:30Z",
  "routing_key": "task.completed",
  "payload": {
    "execution_id": "uuid",
    "agent_id": "uuid",
    "user_id": "uuid",
    "status": "completed",
    "result": {
      "output": "Analysis results...",
      "tokens_used": 1250,
      "execution_time_ms": 3500
    },
    "metrics": {
      "llm_calls": 2,
      "total_cost": 0.05
    }
  }
}
```

### 3.4 é‡è©¦å’Œå†ªç­‰æ€§

#### é‡è©¦ç­–ç•¥

```csharp
public class MessageRetryPolicy
{
    private const int MaxRetries = 3;
    private static readonly TimeSpan[] RetryDelays =
    {
        TimeSpan.FromSeconds(5),    // First retry: 5s
        TimeSpan.FromSeconds(30),   // Second retry: 30s
        TimeSpan.FromMinutes(5)     // Third retry: 5min
    };

    public async Task<bool> ExecuteWithRetryAsync(
        Func<Task> operation,
        string messageId)
    {
        for (int attempt = 0; attempt <= MaxRetries; attempt++)
        {
            try
            {
                await operation();
                return true;
            }
            catch (Exception ex) when (IsTransientError(ex))
            {
                if (attempt == MaxRetries)
                {
                    _logger.LogError(ex,
                        "Max retries reached for {MessageId}", messageId);
                    await SendToDeadLetterQueue(messageId);
                    return false;
                }

                var delay = RetryDelays[attempt];
                _logger.LogWarning(
                    "Retry {Attempt}/{MaxRetries} after {Delay}ms",
                    attempt + 1, MaxRetries, delay.TotalMilliseconds);

                await Task.Delay(delay);
            }
        }
        return false;
    }
}
```

#### å†ªç­‰æ€§è¨­è¨ˆ

```csharp
public class AgentExecutor
{
    public async Task ExecuteAsync(AgentExecutionMessage message)
    {
        var executionId = message.Payload.ExecutionId;

        // 1. Check idempotency (å·²è™•ç†é?)
        var processed = await _cache.GetAsync($"processed:{executionId}");
        if (processed != null)
        {
            _logger.LogInformation(
                "Message {ExecutionId} already processed, skipping",
                executionId);
            return;
        }

        // 2. Acquire distributed lock
        await using var lockHandle = await _distributedLock.AcquireAsync(
            $"exec:{executionId}",
            TimeSpan.FromMinutes(10));

        if (lockHandle == null)
        {
            _logger.LogWarning(
                "Failed to acquire lock for {ExecutionId}", executionId);
            throw new ConcurrencyException("Execution already in progress");
        }

        // 3. Execute business logic
        var result = await ExecuteAgentLogicAsync(message);

        // 4. Mark as processed (TTL: 24h)
        await _cache.SetAsync(
            $"processed:{executionId}",
            "true",
            TimeSpan.FromHours(24));

        // 5. Publish completion event
        await _messageQueue.PublishAsync("task.completed", result);
    }
}
```

---

## 4. å¯¦æ™‚æ•¸æ“šæµ

### 4.1 WebSocket æ¶æ§‹

```mermaid
graph TB
    subgraph "Client Layer"
        Client1[Browser 1]
        Client2[Browser 2]
        Client3[Browser 3]
    end

    subgraph "WebSocket Layer"
        WSServer[Workflow WebSocket Server]
        ConnMgr[Connection Manager]
    end

    subgraph "State Layer"
        CRDT[Y.js CRDT State]
        StateSync[State Sync Engine]
    end

    subgraph "Persistence Layer"
        Redis[(Redis)]
        PostgreSQL[(PostgreSQL)]
    end

    Client1 <-->|ws://| WSServer
    Client2 <-->|ws://| WSServer
    Client3 <-->|ws://| WSServer

    WSServer --> ConnMgr
    ConnMgr --> CRDT
    CRDT <--> StateSync

    StateSync -->|Real-time| Redis
    StateSync -->|Periodic| PostgreSQL
```

### 4.2 å¯¦æ™‚å”ä½œæµç¨‹

#### Scenario 4: VueFlow Workflow å”ä½œç·¨è¼¯

```mermaid
sequenceDiagram
    participant C1 as Client 1
    participant C2 as Client 2
    participant WS as WebSocket Server
    participant CRDT as Y.js CRDT
    participant Redis as Redis
    participant DB as PostgreSQL

    C1->>WS: Connect (workflow_id: abc123)
    WS->>CRDT: Load Shared Document
    CRDT->>Redis: Get Latest State
    Redis-->>CRDT: CRDT State Vector
    CRDT-->>WS: Initial State
    WS-->>C1: Sync State

    C2->>WS: Connect (workflow_id: abc123)
    WS->>CRDT: Join Shared Document
    CRDT-->>WS: Initial State
    WS-->>C2: Sync State

    Note over C1,C2: Both clients in sync

    C1->>WS: Add Node (type: agent, pos: {x:100, y:50})
    WS->>CRDT: Apply Update
    CRDT->>CRDT: Merge with CRDT (Causality)
    CRDT-->>WS: Broadcast Update
    WS-->>C2: Node Added Event
    CRDT->>Redis: Store State (async)

    C2->>WS: Connect Nodes (source: node1, target: node2)
    WS->>CRDT: Apply Update
    CRDT->>CRDT: Merge with CRDT
    CRDT-->>WS: Broadcast Update
    WS-->>C1: Edge Added Event
    CRDT->>Redis: Store State (async)

    Note over WS,DB: Periodic Snapshot (every 30s)
    WS->>DB: Save Workflow Snapshot
    DB-->>WS: Snapshot Saved
```

**CRDT ç‰¹æ€§**:
- **å› æœä¸€è‡´æ€§**: æ“ä½œé †åºè‡ªå‹•è™•ç†
- **è¡çªè§£æ±º**: Last-Write-Wins (LWW) ç­–ç•¥
- **é›¢ç·šæ”¯æŒ**: æ–·ç·šå¾Œé‡é€£è‡ªå‹•åŒæ­¥
- **ç„¡ä¸­å¤®å”èª¿**: å»ä¸­å¿ƒåŒ–åˆä½µç®—æ³•

### 4.3 WebSocket æ¶ˆæ¯æ ¼å¼

#### Connection Message

```json
{
  "type": "connect",
  "workflow_id": "abc123",
  "user_id": "user456",
  "client_id": "client789",
  "timestamp": "2025-10-30T10:00:00Z"
}
```

#### State Update Message

```json
{
  "type": "update",
  "workflow_id": "abc123",
  "operation": "add_node",
  "payload": {
    "node_id": "node001",
    "node_type": "agent",
    "position": {"x": 100, "y": 50},
    "data": {
      "label": "Data Analyzer",
      "agent_id": "agent123"
    }
  },
  "vector_clock": {
    "client789": 5,
    "client456": 3
  },
  "timestamp": "2025-10-30T10:00:01Z"
}
```

#### Broadcast Message

```json
{
  "type": "broadcast",
  "workflow_id": "abc123",
  "from_client": "client789",
  "operation": "add_node",
  "payload": { /* same as update */ },
  "timestamp": "2025-10-30T10:00:01Z"
}
```

### 4.4 é€£æ¥ç®¡ç†

```typescript
export class ConnectionManager {
  private connections: Map<string, WebSocket[]> = new Map();

  // ç”¨æˆ¶åŠ å…¥ workflow
  public join(workflowId: string, ws: WebSocket, userId: string): void {
    if (!this.connections.has(workflowId)) {
      this.connections.set(workflowId, []);
    }

    this.connections.get(workflowId)!.push(ws);

    // é€šçŸ¥å…¶ä»–ç”¨æˆ¶
    this.broadcast(workflowId, {
      type: 'user_joined',
      user_id: userId,
      timestamp: new Date().toISOString()
    }, ws);

    logger.info(`User ${userId} joined workflow ${workflowId}`);
  }

  // å»£æ’­æ¶ˆæ¯çµ¦æ‰€æœ‰ç”¨æˆ¶ (é™¤äº†ç™¼é€è€…)
  public broadcast(
    workflowId: string,
    message: any,
    exclude?: WebSocket
  ): void {
    const connections = this.connections.get(workflowId) || [];
    const payload = JSON.stringify(message);

    for (const ws of connections) {
      if (ws !== exclude && ws.readyState === WebSocket.OPEN) {
        ws.send(payload);
      }
    }
  }

  // ç”¨æˆ¶é›¢é–‹
  public leave(workflowId: string, ws: WebSocket): void {
    const connections = this.connections.get(workflowId);
    if (!connections) return;

    const index = connections.indexOf(ws);
    if (index !== -1) {
      connections.splice(index, 1);
    }

    // å¦‚æœæ²’æœ‰ç”¨æˆ¶äº†ï¼Œæ¸…ç†è³‡æº
    if (connections.length === 0) {
      this.connections.delete(workflowId);
      this.persistState(workflowId); // æŒä¹…åŒ–æœ€çµ‚ç‹€æ…‹
    }
  }
}
```

---

## 5. ç‹€æ…‹ç®¡ç†ç­–ç•¥

### 5.1 ç‹€æ…‹åˆ†å±¤æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Application State               â”‚
â”‚  (Frontend: React/Vue State)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Session State                    â”‚
â”‚  (Redis: TTL 15min)                     â”‚
â”‚  - User sessions                         â”‚
â”‚  - Execution status cache                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Transient State                  â”‚
â”‚  (Redis: TTL 1h)                        â”‚
â”‚  - Cached query results                  â”‚
â”‚  - Persona templates                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Persistent State                 â”‚
â”‚  (PostgreSQL)                            â”‚
â”‚  - Agents, Workflows, Executions         â”‚
â”‚  - User data, Audit logs                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 ç‹€æ…‹åŒæ­¥ç­–ç•¥

#### 5.2.1 æ¨‚è§€é– (Optimistic Locking)

```csharp
public class Agent
{
    public Guid Id { get; set; }
    public string Name { get; set; }
    public DateTime UpdatedAt { get; set; }

    [ConcurrencyCheck] // EF Core optimistic concurrency
    public byte[] RowVersion { get; set; }
}

public async Task UpdateAgentAsync(Agent agent)
{
    try
    {
        _context.Agents.Update(agent);
        await _context.SaveChangesAsync();
    }
    catch (DbUpdateConcurrencyException ex)
    {
        // æª¢æ¸¬ä¸¦ç™¼è¡çª
        var entry = ex.Entries.Single();
        var databaseValues = await entry.GetDatabaseValuesAsync();

        if (databaseValues == null)
        {
            throw new NotFoundException("Agent was deleted");
        }

        // è¿”å›è¡çªä¿¡æ¯çµ¦å‰ç«¯
        throw new ConcurrencyException(
            "Agent was modified by another user",
            databaseValues);
    }
}
```

#### 5.2.2 æ‚²è§€é– (Pessimistic Locking)

```sql
-- ä½¿ç”¨ FOR UPDATE é–å®šè¡Œ
BEGIN;

SELECT * FROM agents
WHERE id = 'abc123'
FOR UPDATE;

-- åŸ·è¡Œæ›´æ–°æ“ä½œ
UPDATE agents
SET name = 'New Name', updated_at = NOW()
WHERE id = 'abc123';

COMMIT;
```

```csharp
// C# å¯¦ç¾
public async Task<Agent> LockAndUpdateAsync(
    Guid agentId,
    Func<Agent, Task> updateAction)
{
    await using var transaction = await _context.Database
        .BeginTransactionAsync(IsolationLevel.ReadCommitted);

    try
    {
        // FOR UPDATE lock
        var agent = await _context.Agents
            .FromSqlRaw("SELECT * FROM agents WHERE id = {0} FOR UPDATE", agentId)
            .SingleOrDefaultAsync();

        if (agent == null)
            throw new NotFoundException($"Agent {agentId} not found");

        // åŸ·è¡Œæ›´æ–°é‚è¼¯
        await updateAction(agent);

        await _context.SaveChangesAsync();
        await transaction.CommitAsync();

        return agent;
    }
    catch
    {
        await transaction.RollbackAsync();
        throw;
    }
}
```

### 5.3 ç‹€æ…‹è½‰ç§»åœ–

#### Agent Execution State Machine

```mermaid
stateDiagram-v2
    [*] --> Pending: Create Execution
    Pending --> Running: Worker Picks Up
    Running --> Completed: Success
    Running --> Failed: Error
    Running --> Cancelled: User Cancels

    Failed --> Running: Retry (Max 3)
    Failed --> [*]: Max Retries Reached

    Completed --> [*]
    Cancelled --> [*]

    note right of Running
        Timeout: 5 minutes
        Max retries: 3
    end note
```

#### Workflow State Transitions

```mermaid
stateDiagram-v2
    [*] --> Draft: Create Workflow
    Draft --> Active: Publish
    Active --> Paused: User Pauses
    Paused --> Active: Resume
    Active --> Archived: Archive
    Draft --> Archived: Delete Draft
    Archived --> [*]

    note right of Active
        Can execute tasks
        Can be edited
    end note

    note right of Archived
        Read-only
        Cannot execute
    end note
```

---

## 6. æ•¸æ“šä¸€è‡´æ€§æ¨¡å¼

### 6.1 ä¸€è‡´æ€§ç´šåˆ¥

| ç´šåˆ¥ | æè¿° | é©ç”¨å ´æ™¯ | å¯¦ç¾æ–¹å¼ |
|------|------|---------|---------|
| **å¼·ä¸€è‡´æ€§** | ç«‹å³å¯è¦‹æ‰€æœ‰å‰¯æœ¬ | é‡‘èäº¤æ˜“ã€æ¬Šé™è®Šæ›´ | åŒæ­¥è¤‡è£½ + 2PC |
| **æœ€çµ‚ä¸€è‡´æ€§** | å»¶é²å¾Œä¿è­‰ä¸€è‡´ | ç”¨æˆ¶è³‡æ–™ã€Agent metadata | ç•°æ­¥è¤‡è£½ + Event Sourcing |
| **å› æœä¸€è‡´æ€§** | ä¿æŒå› æœé †åº | å”ä½œç·¨è¼¯ã€èŠå¤©æ¶ˆæ¯ | CRDT + Vector Clock |
| **æœƒè©±ä¸€è‡´æ€§** | åŒä¸€æœƒè©±å…§ä¸€è‡´ | ç”¨æˆ¶å€‹äººè¦–åœ– | Sticky Session + Cache |

### 6.2 Saga æ¨¡å¼ (åˆ†å¸ƒå¼äº‹å‹™)

#### Scenario 5: å‰µå»º Agent ä¸¦é—œè¯ Persona

```mermaid
sequenceDiagram
    participant Client
    participant Orchestrator as Saga Orchestrator
    participant AgentSvc as Agent Service
    participant PersonaSvc as Persona Service
    participant DB1 as Agent DB
    participant DB2 as Persona DB

    Client->>Orchestrator: Create Agent with Persona

    Orchestrator->>AgentSvc: 1. Create Agent
    AgentSvc->>DB1: INSERT agent
    DB1-->>AgentSvc: agent_id
    AgentSvc-->>Orchestrator: âœ… Agent Created

    Orchestrator->>PersonaSvc: 2. Link Persona
    PersonaSvc->>DB2: UPDATE persona (agent_id)

    alt Persona Link Success
        DB2-->>PersonaSvc: âœ… Updated
        PersonaSvc-->>Orchestrator: âœ… Linked
        Orchestrator-->>Client: 201 Created
    else Persona Link Failed
        DB2-->>PersonaSvc: âŒ Error
        PersonaSvc-->>Orchestrator: âŒ Failed

        Note over Orchestrator: Compensating Transaction
        Orchestrator->>AgentSvc: COMPENSATE: Delete Agent
        AgentSvc->>DB1: DELETE agent
        DB1-->>AgentSvc: âœ… Deleted
        AgentSvc-->>Orchestrator: âœ… Compensated

        Orchestrator-->>Client: 500 Internal Error
    end
```

#### Saga å”èª¿å™¨å¯¦ç¾

```csharp
public class CreateAgentSaga
{
    private readonly IAgentService _agentService;
    private readonly IPersonaService _personaService;
    private readonly ISagaLogger _logger;

    public async Task<SagaResult> ExecuteAsync(CreateAgentRequest request)
    {
        var sagaId = Guid.NewGuid();
        var compensations = new Stack<Func<Task>>();

        try
        {
            // Step 1: Create Agent
            _logger.LogStep(sagaId, "Creating agent");
            var agent = await _agentService.CreateAsync(request.AgentData);
            compensations.Push(async () =>
                await _agentService.DeleteAsync(agent.Id));

            // Step 2: Link Persona
            _logger.LogStep(sagaId, "Linking persona");
            await _personaService.LinkToAgentAsync(
                request.PersonaId,
                agent.Id);
            compensations.Push(async () =>
                await _personaService.UnlinkFromAgentAsync(request.PersonaId));

            // Step 3: Initialize Agent Executor
            _logger.LogStep(sagaId, "Initializing executor");
            await _agentService.InitializeExecutorAsync(agent.Id);

            _logger.LogSuccess(sagaId);
            return SagaResult.Success(agent);
        }
        catch (Exception ex)
        {
            _logger.LogError(sagaId, ex);

            // Execute compensating transactions in reverse order
            while (compensations.Count > 0)
            {
                var compensate = compensations.Pop();
                try
                {
                    await compensate();
                }
                catch (Exception compensationEx)
                {
                    _logger.LogCompensationError(sagaId, compensationEx);
                }
            }

            return SagaResult.Failed(ex);
        }
    }
}
```

### 6.3 Event Sourcing

```csharp
// Event Store
public abstract class DomainEvent
{
    public Guid EventId { get; set; } = Guid.NewGuid();
    public DateTime Timestamp { get; set; } = DateTime.UtcNow;
    public string EventType { get; set; }
}

public class AgentCreatedEvent : DomainEvent
{
    public Guid AgentId { get; set; }
    public string Name { get; set; }
    public Guid PersonaId { get; set; }
}

public class AgentExecutedEvent : DomainEvent
{
    public Guid AgentId { get; set; }
    public Guid ExecutionId { get; set; }
    public string Status { get; set; }
    public int TokensUsed { get; set; }
}

// Event Store Repository
public class EventStore
{
    private readonly DbContext _context;

    public async Task AppendAsync(Guid aggregateId, DomainEvent @event)
    {
        var eventRecord = new EventRecord
        {
            Id = @event.EventId,
            AggregateId = aggregateId,
            EventType = @event.GetType().Name,
            EventData = JsonSerializer.Serialize(@event),
            Timestamp = @event.Timestamp,
            Version = await GetNextVersionAsync(aggregateId)
        };

        _context.Events.Add(eventRecord);
        await _context.SaveChangesAsync();
    }

    public async Task<List<DomainEvent>> GetEventsAsync(Guid aggregateId)
    {
        var records = await _context.Events
            .Where(e => e.AggregateId == aggregateId)
            .OrderBy(e => e.Version)
            .ToListAsync();

        return records
            .Select(r => DeserializeEvent(r.EventType, r.EventData))
            .ToList();
    }

    // Rebuild state from events
    public async Task<Agent> RehydrateAsync(Guid agentId)
    {
        var events = await GetEventsAsync(agentId);
        var agent = new Agent { Id = agentId };

        foreach (var @event in events)
        {
            agent.Apply(@event);
        }

        return agent;
    }
}
```

---

## 7. äº‹å‹™ç®¡ç†

### 7.1 æœ¬åœ°äº‹å‹™ (Single Database)

```csharp
public async Task<Agent> CreateAgentWithTemplatesAsync(
    CreateAgentRequest request)
{
    await using var transaction = await _context.Database
        .BeginTransactionAsync(IsolationLevel.ReadCommitted);

    try
    {
        // 1. Create agent
        var agent = new Agent
        {
            Id = Guid.NewGuid(),
            Name = request.Name,
            PersonaId = request.PersonaId,
            CreatedAt = DateTime.UtcNow
        };
        _context.Agents.Add(agent);
        await _context.SaveChangesAsync();

        // 2. Create agent plugins
        foreach (var pluginRequest in request.Plugins)
        {
            var plugin = new AgentPlugin
            {
                Id = Guid.NewGuid(),
                AgentId = agent.Id,
                Name = pluginRequest.Name,
                Config = pluginRequest.Config
            };
            _context.AgentPlugins.Add(plugin);
        }
        await _context.SaveChangesAsync();

        // 3. Initialize agent executor
        await _executorService.InitializeAsync(agent.Id);

        await transaction.CommitAsync();
        return agent;
    }
    catch (Exception ex)
    {
        await transaction.RollbackAsync();
        _logger.LogError(ex, "Failed to create agent {Name}", request.Name);
        throw;
    }
}
```

### 7.2 åˆ†å¸ƒå¼äº‹å‹™ (Two-Phase Commit)

```csharp
public class TwoPhaseCommitCoordinator
{
    private readonly List<ITransactionalResource> _participants;

    public async Task<bool> ExecuteAsync()
    {
        var transactionId = Guid.NewGuid();

        // Phase 1: PREPARE
        _logger.LogInformation("Starting 2PC transaction {TxId}", transactionId);

        var prepareResults = new List<bool>();
        foreach (var participant in _participants)
        {
            var result = await participant.PrepareAsync(transactionId);
            prepareResults.Add(result);

            if (!result)
            {
                _logger.LogWarning(
                    "Participant {Name} failed PREPARE",
                    participant.Name);
                break;
            }
        }

        // Phase 2: COMMIT or ABORT
        if (prepareResults.All(r => r))
        {
            // All prepared successfully â†’ COMMIT
            foreach (var participant in _participants)
            {
                await participant.CommitAsync(transactionId);
            }
            _logger.LogInformation("2PC transaction {TxId} COMMITTED", transactionId);
            return true;
        }
        else
        {
            // At least one failed â†’ ABORT
            foreach (var participant in _participants)
            {
                await participant.AbortAsync(transactionId);
            }
            _logger.LogWarning("2PC transaction {TxId} ABORTED", transactionId);
            return false;
        }
    }
}

public interface ITransactionalResource
{
    string Name { get; }
    Task<bool> PrepareAsync(Guid transactionId);
    Task CommitAsync(Guid transactionId);
    Task AbortAsync(Guid transactionId);
}
```

**æ³¨æ„**: 2PC åœ¨å¾®æœå‹™æ¶æ§‹ä¸­æ‡‰è¬¹æ…ä½¿ç”¨ï¼Œæ¨è–¦ä½¿ç”¨ **Saga æ¨¡å¼** æˆ– **Event Sourcing** ä»£æ›¿ã€‚

### 7.3 äº‹å‹™éš”é›¢ç´šåˆ¥

| éš”é›¢ç´šåˆ¥ | é«’è®€ | ä¸å¯é‡è¤‡è®€ | å¹»è®€ | æ€§èƒ½ | é©ç”¨å ´æ™¯ |
|---------|------|-----------|------|------|---------|
| **Read Uncommitted** | âœ… | âœ… | âœ… | æœ€é«˜ | æ—¥èªŒã€çµ±è¨ˆ (ä¸éœ€è¦ç²¾ç¢º) |
| **Read Committed** | âŒ | âœ… | âœ… | é«˜ | **é»˜èª** (å¤§å¤šæ•¸å ´æ™¯) |
| **Repeatable Read** | âŒ | âŒ | âœ… | ä¸­ | å ±è¡¨ç”Ÿæˆã€æ‰¹é‡è™•ç† |
| **Serializable** | âŒ | âŒ | âŒ | æœ€ä½ | é‡‘èäº¤æ˜“ã€é—œéµæ“ä½œ |

**æ¨è–¦é…ç½®**:
```csharp
// Default: Read Committed
await _context.Database.BeginTransactionAsync(
    IsolationLevel.ReadCommitted);

// Critical operations: Serializable
await _context.Database.BeginTransactionAsync(
    IsolationLevel.Serializable);
```

---

## 8. æ•¸æ“šæµç›£æ§

### 8.1 é—œéµæŒ‡æ¨™ (KPIs)

#### 8.1.1 åŒæ­¥æµæŒ‡æ¨™

| æŒ‡æ¨™ | ç›®æ¨™ | å‘Šè­¦é–¾å€¼ | ç›£æ§å·¥å…· |
|------|------|---------|---------|
| API éŸ¿æ‡‰æ™‚é–“ (P95) | < 200ms | > 500ms | Prometheus |
| API éŒ¯èª¤ç‡ | < 0.1% | > 1% | Prometheus |
| Cache å‘½ä¸­ç‡ | > 80% | < 60% | Redis INFO |
| Database æŸ¥è©¢æ™‚é–“ | < 50ms | > 100ms | PG slow log |

#### 8.1.2 ç•°æ­¥æµæŒ‡æ¨™

| æŒ‡æ¨™ | ç›®æ¨™ | å‘Šè­¦é–¾å€¼ | ç›£æ§å·¥å…· |
|------|------|---------|---------|
| æ¶ˆæ¯è™•ç†å»¶é² | < 1s | > 5s | RabbitMQ Management |
| éšŠåˆ—ç©å£“ | < 100 | > 1000 | RabbitMQ Management |
| æ¶ˆæ¯é‡è©¦ç‡ | < 5% | > 10% | Application Logs |
| Worker CPU ä½¿ç”¨ç‡ | < 70% | > 85% | Prometheus |

#### 8.1.3 å¯¦æ™‚æµæŒ‡æ¨™

| æŒ‡æ¨™ | ç›®æ¨™ | å‘Šè­¦é–¾å€¼ | ç›£æ§å·¥å…· |
|------|------|---------|---------|
| WebSocket é€£æ¥æ•¸ | - | > 10,000 | Custom Metrics |
| æ¶ˆæ¯å»¶é² (P95) | < 50ms | > 200ms | Custom Metrics |
| CRDT åˆä½µè¡çªç‡ | < 1% | > 5% | Application Logs |
| æ–·ç·šé‡é€£ç‡ | < 5% | > 15% | Custom Metrics |

### 8.2 ç›£æ§å„€è¡¨æ¿ (Grafana)

#### Dashboard 1: API Gateway Metrics

```yaml
panels:
  - title: "Request Rate (req/s)"
    type: graph
    query: rate(http_requests_total[5m])

  - title: "Response Time (P50, P95, P99)"
    type: graph
    queries:
      - histogram_quantile(0.50, http_request_duration_seconds_bucket)
      - histogram_quantile(0.95, http_request_duration_seconds_bucket)
      - histogram_quantile(0.99, http_request_duration_seconds_bucket)

  - title: "Error Rate (%)"
    type: graph
    query: |
      rate(http_requests_total{status=~"5.."}[5m]) /
      rate(http_requests_total[5m]) * 100
    alert:
      condition: value > 1
      severity: warning

  - title: "Cache Hit Rate (%)"
    type: singlestat
    query: |
      redis_keyspace_hits_total /
      (redis_keyspace_hits_total + redis_keyspace_misses_total) * 100
```

#### Dashboard 2: Message Queue Metrics

```yaml
panels:
  - title: "Queue Depth"
    type: graph
    queries:
      - rabbitmq_queue_messages{queue="agent.execute"}
      - rabbitmq_queue_messages{queue="code.execute"}
      - rabbitmq_queue_messages{queue="rag.index"}
    alert:
      condition: value > 1000
      severity: critical

  - title: "Message Throughput (msg/s)"
    type: graph
    query: rate(rabbitmq_queue_messages_published_total[5m])

  - title: "Consumer Lag"
    type: graph
    query: |
      rabbitmq_queue_messages_ready -
      rate(rabbitmq_queue_messages_acked_total[5m])
```

#### Dashboard 3: Database Metrics

```yaml
panels:
  - title: "Query Duration (P95)"
    type: graph
    query: histogram_quantile(0.95, pg_stat_statements_duration_bucket)
    alert:
      condition: value > 100
      severity: warning

  - title: "Active Connections"
    type: singlestat
    query: pg_stat_database_numbackends

  - title: "Deadlocks"
    type: graph
    query: rate(pg_stat_database_deadlocks[5m])
    alert:
      condition: value > 0
      severity: warning

  - title: "Cache Hit Ratio"
    type: singlestat
    query: |
      pg_stat_database_blks_hit /
      (pg_stat_database_blks_hit + pg_stat_database_blks_read) * 100
```

### 8.3 å‘Šè­¦ç­–ç•¥

```yaml
alerting_rules:
  - name: high_api_latency
    condition: http_request_duration_seconds{quantile="0.95"} > 0.5
    duration: 5m
    severity: warning
    notification: slack, email

  - name: high_error_rate
    condition: |
      rate(http_requests_total{status=~"5.."}[5m]) /
      rate(http_requests_total[5m]) > 0.01
    duration: 2m
    severity: critical
    notification: pagerduty, slack

  - name: queue_backlog
    condition: rabbitmq_queue_messages{queue="agent.execute"} > 1000
    duration: 5m
    severity: warning
    notification: slack

  - name: database_slow_queries
    condition: pg_stat_statements_duration{quantile="0.95"} > 0.1
    duration: 10m
    severity: warning
    notification: slack

  - name: cache_hit_rate_low
    condition: redis_keyspace_hits / (redis_keyspace_hits + redis_keyspace_misses) < 0.6
    duration: 15m
    severity: warning
    notification: slack

  - name: websocket_connection_spike
    condition: websocket_active_connections > 10000
    duration: 5m
    severity: warning
    notification: slack
```

### 8.4 åˆ†å¸ƒå¼è¿½è¹¤ (Distributed Tracing)

```csharp
// OpenTelemetry Integration
public class Program
{
    public static void Main(string[] args)
    {
        var builder = WebApplication.CreateBuilder(args);

        // Add OpenTelemetry
        builder.Services.AddOpenTelemetry()
            .WithTracing(tracerProviderBuilder =>
            {
                tracerProviderBuilder
                    .AddAspNetCoreInstrumentation()
                    .AddHttpClientInstrumentation()
                    .AddEntityFrameworkCoreInstrumentation()
                    .AddRedisInstrumentation()
                    .AddSource("AgentService")
                    .AddJaegerExporter(options =>
                    {
                        options.AgentHost = "jaeger";
                        options.AgentPort = 6831;
                    });
            });

        var app = builder.Build();
        app.Run();
    }
}

// Manual span creation
public async Task<Agent> ExecuteAgentAsync(Guid agentId, string input)
{
    using var activity = ActivitySource.StartActivity("ExecuteAgent");
    activity?.SetTag("agent.id", agentId);
    activity?.SetTag("input.length", input.Length);

    try
    {
        var result = await _executor.ExecuteAsync(agentId, input);
        activity?.SetTag("tokens.used", result.TokensUsed);
        return result;
    }
    catch (Exception ex)
    {
        activity?.SetStatus(ActivityStatusCode.Error, ex.Message);
        throw;
    }
}
```

**Trace ç¤ºä¾‹**:
```
Trace: agent-execution-abc123
â”œâ”€ Span: HTTP POST /agents/{id}/execute (150ms)
â”‚  â”œâ”€ Span: Validate JWT Token (5ms)
â”‚  â”œâ”€ Span: Query Agent from DB (12ms)
â”‚  â”œâ”€ Span: Publish to RabbitMQ (3ms)
â”‚  â””â”€ Span: Return 202 Accepted (1ms)
â”‚
â””â”€ Span: Worker Process Message (3200ms)
   â”œâ”€ Span: Load Persona Template (Redis) (8ms)
   â”œâ”€ Span: Call Azure OpenAI (2800ms)
   â”‚  â”œâ”€ Span: Generate Prompt (50ms)
   â”‚  â””â”€ Span: API Request (2750ms)
   â”œâ”€ Span: Code Execution (Docker) (350ms)
   â””â”€ Span: Save Results to DB (42ms)
```

---

## ç¸½çµ

### æ•¸æ“šæµè¨­è¨ˆè¦é»

1. **åˆ†å±¤è¨­è¨ˆ**: åŒæ­¥/ç•°æ­¥/å¯¦æ™‚ä¸‰ç¨®æµæ¸…æ™°åˆ†é›¢
2. **ç·©å­˜ç­–ç•¥**: Redis å¤šå±¤ç·©å­˜æ¸›å°‘ DB å£“åŠ›
3. **ç•°æ­¥è§£è€¦**: RabbitMQ æ¶ˆæ¯éšŠåˆ—è™•ç†é•·æ™‚é–“ä»»å‹™
4. **å¯¦æ™‚å”ä½œ**: WebSocket + CRDT å¯¦ç¾ç„¡è¡çªå”ä½œ
5. **ä¸€è‡´æ€§ä¿è­‰**: æ ¹æ“šæ¥­å‹™éœ€æ±‚é¸æ“‡åˆé©çš„ä¸€è‡´æ€§ç´šåˆ¥
6. **äº‹å‹™ç®¡ç†**: Saga æ¨¡å¼è™•ç†åˆ†å¸ƒå¼äº‹å‹™
7. **ç›£æ§å®Œå–„**: Prometheus + Grafana å…¨æ–¹ä½ç›£æ§

### æ€§èƒ½æŒ‡æ¨™ç¸½çµ

| æ•¸æ“šæµé¡å‹ | å»¶é²ç›®æ¨™ | ååé‡ | å¯é æ€§ |
|-----------|---------|--------|--------|
| åŒæ­¥æµ (REST API) | < 100ms | 1000 req/s | 99.9% |
| ç•°æ­¥æµ (Message Queue) | < 5s | 500 msg/s | 99.99% |
| å¯¦æ™‚æµ (WebSocket) | < 50ms | 10K connections | 99.5% |

### ä¸‹ä¸€æ­¥

âœ… **Part 1 å®Œæˆ**: ç³»çµ±æ¶æ§‹è¨­è¨ˆ (3/3 files)
- 01-SYSTEM-ARCHITECTURE.md
- 02-MICROSERVICES-DESIGN.md
- 03-DATA-FLOW.md

ğŸ“‹ **æ¥ä¸‹ä¾†**: Part 2 - API è¦æ ¼è¨­è¨ˆ
- 04-API-SPECIFICATION.md
- 05-OPENAPI-SPEC.yaml

---

**æ–‡æª”ç‰ˆæœ¬**: v1.0.0
**æœ€å¾Œæ›´æ–°**: 2025-10-30
**ä½œè€…**: AI Workflow Platform Team
